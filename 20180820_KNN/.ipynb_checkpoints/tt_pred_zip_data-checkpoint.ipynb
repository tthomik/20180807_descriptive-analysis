{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handgeschriebene Ziffern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der beiliegenden Beschreibung der Daten habe ich entnommen, dass es sich um handgeschriebene Ziffern handelt. Die mit 16x16 Bildpunkten abgespeichert sind. Der Beschreibung kann ich weiter entnehmen:\n",
    "\n",
    "*\"The data are in two gzipped files, and each line consists of the digit\n",
    "id (0-9) followed by the 256 grayscale values.\"*\n",
    "\n",
    "Es handelt sich also um eine Textdatei in der in jeder Zeile der Wert der geschriebenen Ziffer sowie die 16x16 = 256 Bildpunkte stehen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumber(data, digit):\n",
    "    # wähle alle Zeilen in denen die erste Spalte (Spalte mit den Ziffer) mit 'digit' übereinstimmt\n",
    "    data_number = pd.DataFrame(data[data[0] == digit]) \n",
    "    # schneide die erste Spalte weg und gebe den rest zurück\n",
    "    separated_data = data_number.iloc[:,1:]\n",
    "    return separated_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumberImage(data, digit, aggregation):\n",
    "    # ruft die Hilfsfunktion getNumber auf um alle Bilddaten Daten zu einer Ziffer zu holen\n",
    "    image_data = getNumber(data, digit)\n",
    "    # bilde aus allen Bildern zu der einen Ziffer ein aggrigiertes Bild\n",
    "    if(aggregation == 'median'):\n",
    "        df1 = pd.DataFrame(image_data.median())\n",
    "    else:\n",
    "        df1 = pd.DataFrame(image_data.mean())        \n",
    "    \n",
    "    # wandle das format von (1,256) -> (16,16) und gebe diesen transformierten DataFrame zurück\n",
    "    return df1.values.reshape(16,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(\"CONFIG:\", conf['name'], conf['input_data_name'], \"\\tNum features:\", self.input_data[conf['input_data_name']]['data'].shape[1])? (<ipython-input-4-57073ca59d3a>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-57073ca59d3a>\"\u001b[1;36m, line \u001b[1;32m20\u001b[0m\n\u001b[1;33m    print \"CONFIG:\", conf['name'], conf['input_data_name'], \"\\tNum features:\", self.input_data[conf['input_data_name']]['data'].shape[1]\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(\"CONFIG:\", conf['name'], conf['input_data_name'], \"\\tNum features:\", self.input_data[conf['input_data_name']]['data'].shape[1])?\n"
     ]
    }
   ],
   "source": [
    "class Experiment:\n",
    "    def __init__(self, targets):\n",
    "        self.results = pd.DataFrame(targets, columns=[\"targets\"])\n",
    "\n",
    "        self.input_data = {}\n",
    "        \n",
    "        self.names = []        \n",
    "        self.configs = []\n",
    "\n",
    "        \n",
    "    def get_names(self):\n",
    "        return self.names\n",
    "    \n",
    "    \n",
    "    def get_results(self):\n",
    "        return self.results\n",
    "    \n",
    "    def get_config_map(self):\n",
    "        for conf in self.configs:\n",
    "            print \"CONFIG:\", conf['name'], conf['input_data_name'], \"\\tNum features:\", self.input_data[conf['input_data_name']]['data'].shape[1]\n",
    "    \n",
    "    \n",
    "    def add_input_data(self, name, data, description=\"\"):\n",
    "        self.input_data[name] = {'description': description, 'data': data}\n",
    "    \n",
    "    \n",
    "    def add_config(self, algo, name, input_data_name):\n",
    "        # TODO: add check for dublicate names\n",
    "        if not self.input_data.has_key(input_data_name):\n",
    "            print \"ERROR: feature_set_name not found\"\n",
    "            return \n",
    "        \n",
    "        self.names.append(name)\n",
    "        self.configs.append({ 'name': name, 'algo': algo, 'input_data_name': input_data_name, 'fit': -1})\n",
    "        \n",
    "\n",
    "    def _fit(self, conf):\n",
    "        # get features\n",
    "        input_data = self.input_data[conf['input_data_name']]['data']\n",
    "\n",
    "        # fit the features\n",
    "        print \"Fitting \", conf['name'], \"... \",\n",
    "        \n",
    "        start = time.time() # startzeit\n",
    "        conf['fit'] = conf['algo'].fit(input_data, self.results['targets'])\n",
    "        end = time.time() # startzeit\n",
    "        \n",
    "        print \"done in \", end - start , \"s.\" \n",
    "\n",
    "        \n",
    "    def _predict(self, conf, data):\n",
    "        if data.shape[1] != self.input_data[conf['input_data_name']]['data'].shape[1]:\n",
    "            print \"ERROR: Number of input features does not match (\", conf['name'], \")\"\n",
    "            return\n",
    "        \n",
    "        print \"Predicting data with\", conf['name'], \"... \",\n",
    "        \n",
    "        start = time.time() # startzeit\n",
    "        self.results[conf['name']] = conf['algo'].predict(data)\n",
    "        end = time.time() # startzeit\n",
    "        \n",
    "        print \"done in \", end - start , \"s.\" \n",
    "\n",
    "        \n",
    "    def fit(self):\n",
    "        '''Only trains algorithms if no fit has been calculated before'''\n",
    "        for conf in self.configs:\n",
    "            if conf['fit'] == -1:\n",
    "                self._fit(conf)\n",
    "\n",
    "                \n",
    "    def fit_all(self, data):\n",
    "        '''Trains all algorithms with given data'''\n",
    "        for conf in self.configs:\n",
    "            self._fit(conf)\n",
    "\n",
    "            \n",
    "    def refit(self, data):\n",
    "        '''Retrains all algorithms with given data that have been trained before'''\n",
    "        for conf in self.configs:\n",
    "            if conf['fit'] != -1:\n",
    "                self._fit(conf)\n",
    "\n",
    "                \n",
    "    def predict(self, name, data):\n",
    "        for conf in self.configs:\n",
    "            if conf['fit'] != -1 and conf['name'] == name:\n",
    "                self._predict(conf, data)\n",
    "\n",
    "    def predict_all(self, data):\n",
    "        for conf in self.configs:\n",
    "            if conf['fit'] != -1:\n",
    "                self._predict(conf, data)\n",
    "\n",
    "                \n",
    "    def get_count_df(self, name):\n",
    "        count_matrix = np.zeros((10,10)) \n",
    "        for digit in range(0,10):\n",
    "            cluster_counts = self.results[self.results['targets'] == digit].groupby(name).count()['targets']\n",
    "            for cluster in cluster_counts.keys():\n",
    "                count_matrix[digit][cluster] = cluster_counts[cluster]\n",
    "        \n",
    "        col_names = []\n",
    "        for i in range(0,10):\n",
    "            col_names.append(\"C_\" + str(i))\n",
    "    \n",
    "        return pd.DataFrame(count_matrix, columns=col_names)\n",
    "\n",
    "    def get_norm_df(self, name):\n",
    "        count_df = self.get_count_df(name)\n",
    "        return count_df.divide(count_df.sum(1), axis=0)\n",
    "    \n",
    "    \n",
    "    def get_all_error_rates(self):\n",
    "        error_rates = {}\n",
    "        for conf in self.configs:\n",
    "            if (conf['fit'] != -1) & (conf['name'] in self.results.columns):\n",
    "                error_rates[conf['name']] = self.get_error_rate(conf['name'])\n",
    "        return error_rates\n",
    "                \n",
    "    def get_error_rate(self, name):\n",
    "        '''Determine classification error by identifying best fitting column assignment'''\n",
    "       \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mit header=None, wird die erste Zeile der Datei nicht als Header interpretiert \n",
    "#              (Man könnte den Header in einem solchen Fall als Zeile mit den Spaltenüberschriften bezeichnen)\n",
    "# mit sep=\" \", geben wir an, dass wir das Leerzeichen als Seperator verwenden wollen. \n",
    "#              D.h. zwei durch ein Leerzeichen separierte Werte sollen als zwei Werte eingelesen werden.\n",
    "data = pd.read_csv(\"zip.train\", header=None, sep=\" \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = data.dropna(axis=1, thresh=2) # lass alle Spalten mit mehr als 2 NaN (Not a Number) vom datensatz fallen \n",
    "cleaned_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aus der Beschreibung der Daten wissen wir, dass es sich um die Ziffern und die dazugehörigen Bilder der Größe 16x16 Pixel handelt. Also in jeder Zeile steht in der 0-ten Spalte die Ziffer und in den folgenden 256 Spalten die einzelnen Pixel der Bilder. Also visualisieren wir diese nun einmal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize=(20, 10))\n",
    "for i in range(0,10):\n",
    "    image = getNumberImage(cleaned_data,i,'mean')\n",
    "\n",
    "    # Call signature: subplot(nrows, ncols, index, **kwargs)\n",
    "    plt.subplot(2,5, 1 + i)\n",
    "    plt.imshow(image, cmap='hot', interpolation='none')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification mit KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir nehmen an, dass jeder Bildpunkt ein Wert in dem 256 dimensionalen Raum der reelen Zahlen ist. In diesem Raum haben wir wie im 1-, 2-, oder 3-Dimensionalen auch das euklidische Abstandsmaß."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = cleaned_data.iloc[:,1:].values\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set targets\n",
    "exp = Experiment(cleaned_data[0].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add imputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input featurs are the individual pixels of the image - without transformation\n",
    "exp.add_input_data('256_pixel', input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.add_config(KNeighborsClassifier(n_neighbors=1), 'KNN_1', '256_pixel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.get_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.get_config_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.predict_all(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = exp.get_results()\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0*(results['targets'] == results['KNN_3']).sum()/results['targets'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1.0*(results['targets'] == results['KNN_1']).sum()/results['targets'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 'Train' KNN with zip.train\n",
    "- Validate with zip.test\n",
    "- Calculate training error\n",
    "- Calculate test error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
